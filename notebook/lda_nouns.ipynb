{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anusha/anaconda2/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction import text \n",
    "from pattern.en import parse\n",
    "from pattern.en import pprint\n",
    "from pattern.vector import stem, PORTER, LEMMA\n",
    "punctuation = list(\".,;:!?()[]{}`'\\\"@#$^&*+-|=~_\")\n",
    "from mrjob.job import MRJob\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337211, 36)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"resp\"] = df[\"rating\"] >= df[\"user_rating_avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94625323610439749"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df[\"resp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.94625323610439749, 0.053746763895602512)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priorp = np.mean(df[\"resp\"])\n",
    "priorn = 1 - priorp\n",
    "priorp, priorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "stop.add(\"course\")\n",
    "stop.add(\"course.\")\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[\"user_review_count\"] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[\"content\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"valid_char\"] = df[\"content\"].apply(is_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df[\"valid_char\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"clean_content\"] = df[\"content\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7                                                  love\n",
       "26    wonderful explanation clearly deep understandi...\n",
       "35    learned lot hope youll release angular 20 sure...\n",
       "40    excellent course anthony great job explaining ...\n",
       "48    great far always anthony delivers great qualit...\n",
       "Name: clean_content, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_content\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_parts(text):\n",
    "    nouns = set()\n",
    "    descriptives=set()\n",
    "    \n",
    "    text = text.lower().split()\n",
    "    text = [i for i in text if i not in stop]\n",
    "    text = [i for i in text if i not in punctuation]\n",
    "    text = [i for i in text if len(i) > 1]\n",
    "    for word, pos in nltk.pos_tag(text): # remove the call to nltk.pos_tag if `sentence` is a list of tuples as described above\n",
    "\n",
    "        if pos in ['NN', \"NNP\"]: # feel free to add any other noun tags\n",
    "            nouns.add(word)\n",
    "        elif pos in [\"JJ\", \"JJR\"]:\n",
    "            descriptives.add(word)\n",
    "    return list(nouns), list(descriptives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"review\"] = df[\"clean_content\"].apply(get_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_parts=df.review.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns = [e[0] for e in review_parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46887"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_nouns = [item for sublist in nouns for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Lda = gensim.models.ldamodel.LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel = Lda(doc_term_matrix, num_topics=2, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.018*\"way\" + 0.017*\"time\" + 0.015*\"thing\" + 0.012*\"work\" + 0.010*\"beginner\" + 0.009*\"im\" + 0.009*\"anyone\" + 0.008*\"use\" + 0.007*\"lot\" + 0.007*\"video\"'),\n",
       " (1,\n",
       "  u'0.054*\"instructor\" + 0.041*\"information\" + 0.029*\"thank\" + 0.026*\"lot\" + 0.024*\"explanation\" + 0.021*\"content\" + 0.018*\"material\" + 0.018*\"understand\" + 0.018*\"example\" + 0.013*\"teacher\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1)]\n",
      "[(0, 0.25001156641181005), (1, 0.74998843358819001)]\n",
      "love\n",
      "========================================\n",
      "[(13, 1), (47, 1), (48, 1)]\n",
      "[(0, 0.12778427204630366), (1, 0.87221572795369628)]\n",
      "content learning point\n",
      "========================================\n",
      "[(45, 1), (62, 1), (74, 1), (75, 1)]\n",
      "[(0, 0.8810777943172069), (1, 0.11892220568279317)]\n",
      "way cover perfect knowledge\n",
      "========================================\n",
      "[(6, 1), (13, 1), (17, 1), (60, 1), (61, 1), (91, 1), (107, 1), (108, 1)]\n",
      "[(0, 0.36289018292176883), (1, 0.63710981707823122)]\n",
      "lot content lesson detail everything time start attention\n",
      "========================================\n",
      "[(10, 1), (26, 1)]\n",
      "[(0, 0.4866915613050587), (1, 0.51330843869494125)]\n",
      "thank tony\n",
      "========================================\n",
      "[(127, 1), (155, 1)]\n",
      "[(0, 0.49614729995503543), (1, 0.50385270004496452)]\n",
      "teacher scene\n",
      "========================================\n",
      "[(2, 1), (50, 1)]\n",
      "[(0, 0.16671904541311267), (1, 0.83328095458688733)]\n",
      "material instructor\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for bow in doc_term_matrix[0:100:15]:\n",
    "    print bow\n",
    "    print ldamodel.get_document_topics(bow)\n",
    "    print \" \".join([dictionary[e[0]] for e in bow])\n",
    "    print \"========================================\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj = [e[1] for e in review_parts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46887"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_adj = [item for sublist in adj for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'wonderful',\n",
       " u'deep',\n",
       " 'angular',\n",
       " u'great',\n",
       " u'subject',\n",
       " u'excellent',\n",
       " u'content',\n",
       " u'great',\n",
       " u'old',\n",
       " u'current']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_adj[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adjvo = set(flat_adj)\n",
    "adjvocab ={}\n",
    "for i, word in enumerate(adjvo):\n",
    "    adjvocab[word] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjvocab[\"great\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary_adj = corpora.Dictionary(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7468"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_term_matrix_adj = [dictionary_adj.doc2bow(doc) for doc in adj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46887"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_term_matrix_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "xarray= map(lambda i: \" \".join(list(itertools.chain.from_iterable(i))), adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46887"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resp = df[\"resp\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46887, 46887)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resp), len(xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anusha/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(len(xarray)), train_size=0.7)\n",
    "mask=np.ones(len(xarray), dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.array(xarray)\n",
    "y=np.array(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_xy(X_col, y_col, vectorizer):\n",
    "    X = vectorizer.fit_transform(X_col)\n",
    "    y = y_col\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_likelihood(clf, x, y):\n",
    "    prob = clf.predict_log_proba(x)\n",
    "    negs = y == 0\n",
    "    posivs = ~negs\n",
    "    return prob[negs, 0].sum() + prob[posivs, 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def cv_score(clf, x, y, score_func, nfold=5):\n",
    "    \n",
    "    result = 0\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf, x[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7468"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adjvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = [ 0.1, 1, 5, 10, 50]\n",
    "#min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.5, 0.9]\n",
    "\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "best_alpha = None\n",
    "#best_min_df = None\n",
    "max_loglike = -np.inf\n",
    "\n",
    "for alpha in alphas:        \n",
    "    vectorizer = CountVectorizer(vocabulary=adjvocab)       \n",
    "    aX, ay = make_xy(X, y, vectorizer)\n",
    "    tX=aX[mask]\n",
    "    ty=ay[mask]\n",
    "    clf = MultinomialNB(alpha=alpha)\n",
    "    loglike = cv_score(clf, tX, ty, log_likelihood)\n",
    "\n",
    "    if loglike > max_loglike:\n",
    "        max_loglike = loglike\n",
    "        best_alpha = alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.84\n",
      "Accuracy on test data:     0.84\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=adjvocab)\n",
    "aX, ay = make_xy(X, y, vectorizer)\n",
    "tX=aX[mask]\n",
    "ty=ay[mask]\n",
    "teX=aX[~mask]\n",
    "tey=ay[~mask]\n",
    "\n",
    "clfnew = MultinomialNB(alpha=best_alpha).fit(tX, ty)\n",
    "\n",
    "training_accuracy = clfnew.score(tX, ty)\n",
    "test_accuracy = clfnew.score(teX, tey)\n",
    "\n",
    "print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "print \"Accuracy on test data:     %0.2f\" % (test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logpositives=dict(zip(vectorizer.get_feature_names(),clfnew.feature_log_prob_[1]))\n",
    "lognegatives=dict(zip(vectorizer.get_feature_names(),clfnew.feature_log_prob_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'yellow',\n",
       " u'drawpose',\n",
       " u'francesco',\n",
       " u'nodejavascript',\n",
       " u'localized',\n",
       " u'unblocked',\n",
       " 'fouryear',\n",
       " u'unanswered',\n",
       " u'accrej',\n",
       " u'shortcutshelpful',\n",
       " u'goodpractical',\n",
       " u'informativeif',\n",
       " u'digit',\n",
       " 'rational',\n",
       " u'helpfulinsightful',\n",
       " 'uncertain',\n",
       " 'werid',\n",
       " u'invokable',\n",
       " u'prize',\n",
       " u'customizable',\n",
       " u'rabbitmq',\n",
       " u'oooh',\n",
       " u'straight',\n",
       " u'muchengagingpractical',\n",
       " u'tired',\n",
       " u'wellspoken',\n",
       " u'elegant',\n",
       " 'second',\n",
       " u'inanimate',\n",
       " u'admire',\n",
       " u'excelllent',\n",
       " u'everthibg',\n",
       " u'hreflite',\n",
       " u'designing',\n",
       " u'resilient',\n",
       " u'numeral',\n",
       " u'specialist',\n",
       " u'widget',\n",
       " u'hero',\n",
       " 'intentioned',\n",
       " u'specialise',\n",
       " u'affiliated',\n",
       " 'conversational',\n",
       " u'gobut',\n",
       " u'uplifting',\n",
       " u'elaborate',\n",
       " u'controversy',\n",
       " u'military',\n",
       " u'numerical',\n",
       " u'golden',\n",
       " u'divide',\n",
       " u'breaksdown',\n",
       " 'explained',\n",
       " u'lengthen',\n",
       " u'brought',\n",
       " u'unix',\n",
       " u'notary',\n",
       " u'udacitys',\n",
       " u'browse',\n",
       " u'dnn',\n",
       " u'webpack',\n",
       " u'understanable',\n",
       " u'strike',\n",
       " u'holy',\n",
       " 'successful',\n",
       " u'jms',\n",
       " u'hurt',\n",
       " u'hole',\n",
       " u'hold',\n",
       " 'addon',\n",
       " u'pursue',\n",
       " u'accomplishment',\n",
       " 'temas',\n",
       " 'maximilian',\n",
       " u'reword',\n",
       " u'postgressql',\n",
       " u'erratica',\n",
       " u'organized',\n",
       " u'semiadvanced',\n",
       " 'wirklich',\n",
       " u'want',\n",
       " u'absolute',\n",
       " u'boredtwo',\n",
       " u'shiki',\n",
       " u'syntactic',\n",
       " u'travel',\n",
       " u'followcontactable',\n",
       " u'feature',\n",
       " u'geojson',\n",
       " u'revisit',\n",
       " u'nontrivial',\n",
       " u'playback',\n",
       " u'exelent',\n",
       " u'hop',\n",
       " 'significance',\n",
       " u'hi',\n",
       " u'preferable',\n",
       " u'credential',\n",
       " u'utilise',\n",
       " u'typed',\n",
       " u'diagram',\n",
       " u'wrong',\n",
       " 'monolithic',\n",
       " u'effective',\n",
       " 'understanderble',\n",
       " u'nichify',\n",
       " u'alias',\n",
       " u'selfimprovement',\n",
       " 'democratic',\n",
       " u'nonsensical',\n",
       " u'feedback',\n",
       " u'dreamed',\n",
       " 'vary',\n",
       " u'prophecygo',\n",
       " u'fit',\n",
       " u'burndown',\n",
       " u'tutoral',\n",
       " u'fix',\n",
       " u'diffrent',\n",
       " 'udemythank',\n",
       " u'helpfulthe',\n",
       " u'hidden',\n",
       " u'fin',\n",
       " u'easier',\n",
       " u'undercut',\n",
       " u'iside',\n",
       " u'enrich',\n",
       " u'interrupt',\n",
       " u'multidimensional',\n",
       " u'silver',\n",
       " 'saddened',\n",
       " u'structural',\n",
       " u'walkthrough',\n",
       " u'ipeasant',\n",
       " u'wooden',\n",
       " u'arrow',\n",
       " u'debug',\n",
       " u'whim',\n",
       " u'financial',\n",
       " u'makibg',\n",
       " u'nonenglish',\n",
       " u'legwork',\n",
       " u'fortnight',\n",
       " u'cathedral',\n",
       " u'whit',\n",
       " u'message',\n",
       " u'overwrite',\n",
       " u'toptic',\n",
       " u'ha',\n",
       " u'mayan',\n",
       " u'freeze',\n",
       " u'rd',\n",
       " u'encourage',\n",
       " u'adapt',\n",
       " u'rc',\n",
       " u'startreview',\n",
       " u'abramovs',\n",
       " u'foundation',\n",
       " u'levellove',\n",
       " u'expertisesome',\n",
       " u'aspnetc',\n",
       " u'sensory',\n",
       " u'clearclear',\n",
       " u'sheet',\n",
       " 'strawman',\n",
       " u'gameplay',\n",
       " u'enormous',\n",
       " u'r2',\n",
       " u'commented',\n",
       " u'silicon',\n",
       " 'disturbed',\n",
       " u'speedy',\n",
       " u'atp',\n",
       " u'uiux',\n",
       " u'appreciable',\n",
       " 'wasy',\n",
       " u'wast',\n",
       " u'wash',\n",
       " u'teachersmuch',\n",
       " u'clarity',\n",
       " 'evin',\n",
       " u'service',\n",
       " u'similarly',\n",
       " u'engagement',\n",
       " u'foolproof',\n",
       " u'needed',\n",
       " 'master',\n",
       " u'professsional',\n",
       " u'hypothetical',\n",
       " u'gilbert',\n",
       " u'faintofheart',\n",
       " u'bitter',\n",
       " u'listen',\n",
       " u'coursera',\n",
       " u'wisdom',\n",
       " u'rectified',\n",
       " u'swish',\n",
       " u'ahmed',\n",
       " u'showed',\n",
       " u'codelike',\n",
       " u'tree',\n",
       " u'rusty',\n",
       " u'project',\n",
       " u'showes',\n",
       " u'idle',\n",
       " u'skimmed',\n",
       " 'tooincredible',\n",
       " 'feeling',\n",
       " 'esta',\n",
       " u'spectrum',\n",
       " u'width',\n",
       " u'increment',\n",
       " u'uptostandard',\n",
       " u'foundational',\n",
       " u'wholesome',\n",
       " u'hub',\n",
       " u'responsible',\n",
       " u'gripe',\n",
       " u'recommended',\n",
       " 'absorbed',\n",
       " u'amusing',\n",
       " u'object',\n",
       " u'pythonic',\n",
       " u'simplify',\n",
       " u'standardbasic',\n",
       " u'macbook',\n",
       " u'dummy',\n",
       " u'jupyter',\n",
       " u'professor',\n",
       " u'camp',\n",
       " u'huw',\n",
       " u'tech',\n",
       " u'jqueryajax',\n",
       " u'incomplete',\n",
       " u'incorporate',\n",
       " u'teresa',\n",
       " u'benificial',\n",
       " u'gauge',\n",
       " u'asia',\n",
       " 'participate',\n",
       " u'lethal',\n",
       " u'reinvented',\n",
       " u'apace',\n",
       " u'busy',\n",
       " u'layout',\n",
       " u'headline',\n",
       " u'menu',\n",
       " u'whenwhy',\n",
       " u'theme',\n",
       " u'touched',\n",
       " u'rich',\n",
       " u'didactical',\n",
       " u'themi',\n",
       " 'foremost',\n",
       " u'confusig',\n",
       " u'prefinal',\n",
       " u'release',\n",
       " u'respond',\n",
       " 'mandatory',\n",
       " u'heregood',\n",
       " 'fair',\n",
       " 'clarified',\n",
       " u'peripheral',\n",
       " 'atef',\n",
       " u'radius',\n",
       " u'result',\n",
       " u'fail',\n",
       " u'resigned',\n",
       " u'hammer',\n",
       " u'best',\n",
       " u'wikipedia',\n",
       " u'loti',\n",
       " u'score',\n",
       " u'irl',\n",
       " 'melissa',\n",
       " u'conceptual',\n",
       " u'lota',\n",
       " u'skimpy',\n",
       " u'indecisive',\n",
       " u'extend',\n",
       " u'nature',\n",
       " u'interestingthey',\n",
       " u'extent',\n",
       " u'heartbeast',\n",
       " u'mvc5',\n",
       " u'accident',\n",
       " u'refinement',\n",
       " u'fallacious',\n",
       " 'coursewhich',\n",
       " u'planned',\n",
       " u'logic',\n",
       " u'login',\n",
       " u'argue',\n",
       " u'adapted',\n",
       " 'asked',\n",
       " 'stuffthis',\n",
       " u'pre',\n",
       " u'vail',\n",
       " u'thisdo',\n",
       " 'ofcomical',\n",
       " u'approachperspective',\n",
       " u'diff',\n",
       " u'organisational',\n",
       " u'partscourse',\n",
       " u'customisation',\n",
       " u'relearnt',\n",
       " 'pinball',\n",
       " u'chrome',\n",
       " u'fro',\n",
       " u'much',\n",
       " u'dont',\n",
       " u'explicadas',\n",
       " 'thisthe',\n",
       " u'dry',\n",
       " u'graphical',\n",
       " u'recomend',\n",
       " u'eastern',\n",
       " u'comprehensiveness',\n",
       " u'davy',\n",
       " u'wish',\n",
       " u'dave',\n",
       " u'child',\n",
       " u'unexperienced',\n",
       " u'chill',\n",
       " u'gritty',\n",
       " u'professionally',\n",
       " u'employ',\n",
       " u'unos',\n",
       " u'toolkit',\n",
       " u'weirdness',\n",
       " u'letdown',\n",
       " u'informativelots',\n",
       " u'upscale',\n",
       " u'trusted',\n",
       " u'dhe',\n",
       " u'cumulative',\n",
       " u'haphazard',\n",
       " u'split',\n",
       " u'european',\n",
       " u'voiceover',\n",
       " u'issac',\n",
       " 'issam',\n",
       " u'updown',\n",
       " u'againstart',\n",
       " u'preachy',\n",
       " u'topi',\n",
       " u'supper',\n",
       " 'tune',\n",
       " u'lucas',\n",
       " 'stupendous',\n",
       " u'isholiday',\n",
       " u'wellfocused',\n",
       " u'academic',\n",
       " u'academia',\n",
       " u'corporate',\n",
       " u'sleepy',\n",
       " u'previous',\n",
       " 'handshake',\n",
       " u'remedial',\n",
       " u'ease',\n",
       " u'easy',\n",
       " u'showsyear',\n",
       " 'east',\n",
       " u'quirk',\n",
       " u'possible',\n",
       " u'firmer',\n",
       " u'indicative',\n",
       " u'shadow',\n",
       " u'unique',\n",
       " u'psychological',\n",
       " 'articulated',\n",
       " u'alreday',\n",
       " 'instantlythis',\n",
       " u'beneficial',\n",
       " u'right',\n",
       " u'old',\n",
       " u'ole',\n",
       " u'crowd',\n",
       " u'captive',\n",
       " u'cloud9nitrous',\n",
       " u'animate',\n",
       " u'creep',\n",
       " u'bottom',\n",
       " u'rehearse',\n",
       " u'creative',\n",
       " u'witty',\n",
       " u'fogive',\n",
       " u'umm',\n",
       " u'uml',\n",
       " u'palatable',\n",
       " u'indetail',\n",
       " u'javascrpit',\n",
       " u'defensive',\n",
       " u'memorable',\n",
       " u'behavour',\n",
       " u'toplevel',\n",
       " u'untiy',\n",
       " u'lacked',\n",
       " u'successive',\n",
       " 'som',\n",
       " u'mba',\n",
       " 'soo',\n",
       " u'mocha',\n",
       " u'thankful',\n",
       " u'ngfor',\n",
       " u'wrap',\n",
       " u'whwn',\n",
       " u'unambiguous',\n",
       " u'support',\n",
       " u'knowing',\n",
       " u'uncluttered',\n",
       " u'absolutely',\n",
       " u'greggs',\n",
       " u'wordpress',\n",
       " u'greatness',\n",
       " u'overhead',\n",
       " 'happy',\n",
       " u'paypal',\n",
       " u'understandable',\n",
       " u'hamedani',\n",
       " u'undestanding',\n",
       " u'silliness',\n",
       " u'inside',\n",
       " u'peso',\n",
       " u'tictactoe',\n",
       " u'languagesthe',\n",
       " u'tonne',\n",
       " u'proud',\n",
       " u'liberal',\n",
       " u'achive',\n",
       " u'textbook',\n",
       " u'meagre',\n",
       " u'exist',\n",
       " u'informativethe',\n",
       " 'angular2cli',\n",
       " u'relay',\n",
       " u'indexingi',\n",
       " u'grammatical',\n",
       " u'zany',\n",
       " u'ambitious',\n",
       " u'trainingive',\n",
       " u'ferrari',\n",
       " u'superfluous',\n",
       " u'wart',\n",
       " 'intend',\n",
       " u'twentyfive',\n",
       " 'pheomenal',\n",
       " u'demonstrative',\n",
       " u'transported',\n",
       " 'sesame',\n",
       " u'intent',\n",
       " u'variable',\n",
       " u'tims',\n",
       " u'unshipped',\n",
       " u'serialized',\n",
       " u'novicebutnotnewbie',\n",
       " u'push',\n",
       " u'disorganization',\n",
       " u'breadth',\n",
       " u'newbie',\n",
       " u'osi',\n",
       " u'tampa',\n",
       " u'manytomany',\n",
       " u'jarring',\n",
       " u'chair',\n",
       " u'uneven',\n",
       " u'freelance',\n",
       " 'vez',\n",
       " u'vey',\n",
       " u'aweseome',\n",
       " u'understandand',\n",
       " u'downloading',\n",
       " u'cheap',\n",
       " u'liiiittle',\n",
       " u'embark',\n",
       " u'exact',\n",
       " u'minute',\n",
       " u'cooky',\n",
       " 'ckear',\n",
       " 'leave',\n",
       " u'solved',\n",
       " u'team',\n",
       " u'reactangular',\n",
       " u'unaware',\n",
       " u'prevent',\n",
       " u'spiritual',\n",
       " u'insignificant',\n",
       " u'htmlcss',\n",
       " u'sign',\n",
       " u'functionnal',\n",
       " u'anaconda',\n",
       " u'headset',\n",
       " u'educate',\n",
       " u'midsentence',\n",
       " 'freakn',\n",
       " u'current',\n",
       " u'ngapp',\n",
       " u'boost',\n",
       " u'performant',\n",
       " u'dropdown',\n",
       " u'honour',\n",
       " 'understanding',\n",
       " u'upgrade',\n",
       " u'contaigeous',\n",
       " 'address',\n",
       " u'alone',\n",
       " u'along',\n",
       " u'enroll',\n",
       " 'brilliant',\n",
       " u'studied',\n",
       " u'queue',\n",
       " u'accomplished',\n",
       " 'ineffective',\n",
       " u'vendorjs',\n",
       " u'love',\n",
       " u'prefer',\n",
       " u'logical',\n",
       " u'marvelous',\n",
       " u'fake',\n",
       " u'forefront',\n",
       " u'sky',\n",
       " u'angularcli',\n",
       " u'working',\n",
       " u'positive',\n",
       " u'angry',\n",
       " u'opposed',\n",
       " u'wondering',\n",
       " u'etude',\n",
       " u'scope',\n",
       " u'sunburst',\n",
       " u'theoretical',\n",
       " u'loving',\n",
       " u'scratched',\n",
       " u'introducing',\n",
       " u'afford',\n",
       " u'apparent',\n",
       " u'oregon',\n",
       " u'visual',\n",
       " u'appendix',\n",
       " u'virtue',\n",
       " u'resourcesextra',\n",
       " u'behalf',\n",
       " u'hussey',\n",
       " u'overloaded',\n",
       " u'vega',\n",
       " u'slowness',\n",
       " u'following',\n",
       " u'forext',\n",
       " u'awesome',\n",
       " u'understatement',\n",
       " 'incremental',\n",
       " u'offense',\n",
       " u'echoy',\n",
       " u'listens',\n",
       " u'ramesh',\n",
       " u'deserves',\n",
       " u's3',\n",
       " u'llega',\n",
       " 'fps',\n",
       " u'elephant',\n",
       " u'optimal',\n",
       " u'xhtml',\n",
       " u'userauthentication',\n",
       " u'parameter',\n",
       " u'mormon',\n",
       " u'undertook',\n",
       " u'entrylevel',\n",
       " u'spot',\n",
       " u'javascriptthe',\n",
       " u'improving',\n",
       " 'data',\n",
       " u'stress',\n",
       " u'natural',\n",
       " u'correlate',\n",
       " 'conscious',\n",
       " u'applicant',\n",
       " 'sw',\n",
       " u'scrivener',\n",
       " u'sandbox',\n",
       " u'sm',\n",
       " u'sa',\n",
       " u'sg',\n",
       " u'sf',\n",
       " u'impactful',\n",
       " u'innocuous',\n",
       " u'bush',\n",
       " u'webpage',\n",
       " u'copious',\n",
       " 'knnowledgeable',\n",
       " u'unfavorable',\n",
       " u'chartpivot',\n",
       " u'thoughtfulness',\n",
       " 'avid',\n",
       " 'derive',\n",
       " u'overhaul',\n",
       " u'thumb',\n",
       " u'lackluster',\n",
       " u'torn',\n",
       " u'hot',\n",
       " u'bcryptjs',\n",
       " u'nontheless',\n",
       " u'limbo',\n",
       " 'smarter',\n",
       " u'endend',\n",
       " u'compelled',\n",
       " u'fomerhorrible',\n",
       " u'plunk',\n",
       " u'revert',\n",
       " u'appropriate',\n",
       " u'bowling',\n",
       " u'theoratical',\n",
       " u'receipt',\n",
       " u'tonymy',\n",
       " u'generosityhis',\n",
       " 'awsole',\n",
       " u'giftedalso',\n",
       " u'canvas',\n",
       " u'contained',\n",
       " u'internet',\n",
       " u'formula',\n",
       " 'learningi',\n",
       " u'hibernate',\n",
       " u'seventh',\n",
       " u'quite',\n",
       " u'disrespect',\n",
       " 'lucrative',\n",
       " u'easytolearn',\n",
       " u'byte',\n",
       " u'remainder',\n",
       " u'iterative',\n",
       " u'modest',\n",
       " u'timelined',\n",
       " u'initiate',\n",
       " u'undesirable',\n",
       " u'router',\n",
       " u'jumbled',\n",
       " u'intuition',\n",
       " u'spoken',\n",
       " u'nested',\n",
       " u'periodical',\n",
       " u'spanish',\n",
       " u'open',\n",
       " u'looong',\n",
       " u'bite',\n",
       " u'structured',\n",
       " u'indicate',\n",
       " u'typing',\n",
       " u'oversimplified',\n",
       " u'ableton',\n",
       " u'custombuild',\n",
       " 'ridiculous',\n",
       " u'photographic',\n",
       " u'vevvry',\n",
       " u'stle',\n",
       " 'translate',\n",
       " u'depressed',\n",
       " u'rival',\n",
       " u'udemys',\n",
       " u'future',\n",
       " u'arun',\n",
       " u'understandreally',\n",
       " u'proactive',\n",
       " 'professionalstep',\n",
       " u'prospect',\n",
       " u'illness',\n",
       " u'san',\n",
       " 'graspill',\n",
       " 'sal',\n",
       " u'turned',\n",
       " u'argument',\n",
       " u'alley',\n",
       " u'sad',\n",
       " u'say',\n",
       " u'sax',\n",
       " u'fortunatelythe',\n",
       " u'sas',\n",
       " u'sap',\n",
       " u'saw',\n",
       " u'sat',\n",
       " u'doubleparsedouble',\n",
       " u'aproach',\n",
       " u'somethings',\n",
       " u'instructed',\n",
       " u'note',\n",
       " u'understandplus',\n",
       " u'take',\n",
       " u'opposite',\n",
       " u'knew',\n",
       " u'invoked',\n",
       " u'inserted',\n",
       " u'elaborative',\n",
       " u'impproved',\n",
       " u'downvisual',\n",
       " u'phil',\n",
       " u'drive',\n",
       " u'jittery',\n",
       " u'redirected',\n",
       " u'salt',\n",
       " u'transacript',\n",
       " u'lotus',\n",
       " u'bright',\n",
       " u'inconsistent',\n",
       " u'bitesize',\n",
       " u'aggressive',\n",
       " u'imagined',\n",
       " u'slot',\n",
       " u'slow',\n",
       " 'punchy',\n",
       " 'recomended',\n",
       " u'djangoflask',\n",
       " u'ellegant',\n",
       " u'robs',\n",
       " u'himher',\n",
       " u'acupressure',\n",
       " u'dynamodb',\n",
       " u'foward',\n",
       " u'slog',\n",
       " u'equipped',\n",
       " u'nonce',\n",
       " u'directed',\n",
       " u'awesomeif',\n",
       " u'assistant',\n",
       " u'simplistic',\n",
       " u'awesomeiv',\n",
       " u'noncs',\n",
       " 'clearest',\n",
       " u'embedd',\n",
       " u'prime',\n",
       " u'resource',\n",
       " u'bestselling',\n",
       " u'artist',\n",
       " u'assimilate',\n",
       " 'unrealcoursecom',\n",
       " u'worried',\n",
       " u'tenured',\n",
       " u'xmas',\n",
       " u'concurrency',\n",
       " u'excepional',\n",
       " u'beingglad',\n",
       " u'gns3',\n",
       " u'anyways',\n",
       " u'sharmic',\n",
       " u'refresher',\n",
       " u'jumped',\n",
       " u'enjoyd',\n",
       " u'wellput',\n",
       " u'refreshed',\n",
       " u'enjoys',\n",
       " u'uk',\n",
       " u'vertical',\n",
       " u'screen',\n",
       " u'concentrate',\n",
       " u'spare',\n",
       " u'spark',\n",
       " u'progessive',\n",
       " u'undermine',\n",
       " u'concentrated',\n",
       " u'friendsben',\n",
       " u'intuitional',\n",
       " u'many',\n",
       " 'stream',\n",
       " u'stufffor',\n",
       " 'extinct',\n",
       " 'narcissistic',\n",
       " u'howuseful',\n",
       " u'testimonial',\n",
       " u'stretch',\n",
       " u'throttled',\n",
       " u'defined',\n",
       " u'practised',\n",
       " 'combined',\n",
       " u'reflective',\n",
       " u'prototype',\n",
       " u'ideasstory',\n",
       " u'enable',\n",
       " u'gist',\n",
       " u'geonear',\n",
       " u'observe',\n",
       " u'abject',\n",
       " u'former',\n",
       " u'reactreactrouter',\n",
       " u'searcher',\n",
       " u'admirable',\n",
       " u'understandlike',\n",
       " u'graphed',\n",
       " u'ive',\n",
       " u'reverse',\n",
       " u'trello',\n",
       " u'engaged',\n",
       " u'schooli',\n",
       " u'dubious',\n",
       " u'obtuse',\n",
       " u'engages',\n",
       " u'binary',\n",
       " 'verified',\n",
       " u'preparatory',\n",
       " u'underestimate',\n",
       " u'issueit',\n",
       " u'breakdown',\n",
       " u'enthousiat',\n",
       " u'newfound',\n",
       " u'knowhow',\n",
       " u'nononsense',\n",
       " u'advertisement',\n",
       " u'unmanageable',\n",
       " u'proespective',\n",
       " u'cheery',\n",
       " u'awesomeness',\n",
       " u'undefined',\n",
       " 'customized',\n",
       " u'pacing',\n",
       " u'subsubject',\n",
       " u'therapy',\n",
       " u'nosql',\n",
       " u'advancedpro',\n",
       " u'cohesive',\n",
       " u'rest',\n",
       " u'scrape',\n",
       " u'angel',\n",
       " u'inaudible',\n",
       " u'weekly',\n",
       " u'loftier',\n",
       " u'grounded',\n",
       " u'formative',\n",
       " u'joyful',\n",
       " u'excellentsimple',\n",
       " 'monthsnow',\n",
       " u'unerring',\n",
       " u'imagesyour',\n",
       " u'dark',\n",
       " u'unedited',\n",
       " u'darn',\n",
       " u'vague',\n",
       " u'dare',\n",
       " u'sensational',\n",
       " u'createreactnative',\n",
       " u'smm',\n",
       " u'crystalclear',\n",
       " u'satisfactory',\n",
       " u'pushy',\n",
       " 'conditional',\n",
       " 'rereview',\n",
       " u'supplementary',\n",
       " u'diving',\n",
       " u'divine',\n",
       " 'excelent',\n",
       " u'reparative',\n",
       " u'noob',\n",
       " u'knowledageable',\n",
       " u'favourite',\n",
       " u'unoptimized',\n",
       " 'lottutor',\n",
       " u'biased',\n",
       " u'scientific',\n",
       " u'intimate',\n",
       " u'internship',\n",
       " u'iconic',\n",
       " u'addicted',\n",
       " u'prewritten',\n",
       " u'standpoint',\n",
       " u'amped',\n",
       " u'stone',\n",
       " u'acf',\n",
       " u'favorite',\n",
       " u'meal',\n",
       " u'practicable',\n",
       " u'act',\n",
       " u'linebyline',\n",
       " u'unpacks',\n",
       " u'luck',\n",
       " u'somehwat',\n",
       " u'springboot',\n",
       " u'flawed',\n",
       " u'pationate',\n",
       " u'mdn',\n",
       " 'freaken',\n",
       " 'hep',\n",
       " u'glean',\n",
       " u'mindless',\n",
       " u'brazilian',\n",
       " u'springboard',\n",
       " u'bubble',\n",
       " 'punctuation',\n",
       " u'complete',\n",
       " u'verbatim',\n",
       " u'peaceful',\n",
       " u'societal',\n",
       " u'mich',\n",
       " u'recommendi',\n",
       " u'handsome',\n",
       " u'pull',\n",
       " u'rush',\n",
       " u'arsenalhave',\n",
       " u'dirty',\n",
       " u'sitesoundphysical',\n",
       " u'agree',\n",
       " u'detailed',\n",
       " u'ac',\n",
       " u'ab',\n",
       " u'ae',\n",
       " u'gratuitous',\n",
       " u'exhausted',\n",
       " u'ah',\n",
       " 'forgot',\n",
       " u'al',\n",
       " 'laminated',\n",
       " u'watcher',\n",
       " u'tshirt',\n",
       " u'ar',\n",
       " u'au',\n",
       " u'fumbling',\n",
       " u'watched',\n",
       " u'az',\n",
       " u'novice',\n",
       " u'graduate',\n",
       " u'tight',\n",
       " u'unparalleled',\n",
       " u'spatial',\n",
       " u'macsql',\n",
       " u'incomprehensible',\n",
       " u'finallyi',\n",
       " u'vocabulary',\n",
       " 'slant',\n",
       " u'seriousness',\n",
       " u'inaccuracy',\n",
       " u'a2',\n",
       " u'a4',\n",
       " u'overdelivered',\n",
       " u'affilaite',\n",
       " u'tricky',\n",
       " u'natalie',\n",
       " u'cpc',\n",
       " u'upthank',\n",
       " u'explane',\n",
       " 'gradient',\n",
       " u'mimic',\n",
       " u'behavioral',\n",
       " u'cpt',\n",
       " 'original',\n",
       " u'sci',\n",
       " u'consider',\n",
       " u'beware',\n",
       " u'fairness',\n",
       " u'frontendangular',\n",
       " 'careful',\n",
       " u'tu',\n",
       " 'rf',\n",
       " u'tail',\n",
       " u'highquality',\n",
       " u'ti',\n",
       " u'fivestar',\n",
       " u'smile',\n",
       " u'te',\n",
       " u'norm',\n",
       " u'ta',\n",
       " u'returned',\n",
       " u'puzzled',\n",
       " u'candid',\n",
       " u'diary',\n",
       " u'apropriated',\n",
       " u'manageable',\n",
       " u'kreponic',\n",
       " u'noobs',\n",
       " u'ro',\n",
       " 'althought',\n",
       " 'marvellous',\n",
       " u'large',\n",
       " u'pesky',\n",
       " u'adjust',\n",
       " u'usablerepeatable',\n",
       " u'shanis',\n",
       " u'small',\n",
       " u'abbreviated',\n",
       " u'woocommerce',\n",
       " u'methodical',\n",
       " u'sync',\n",
       " u'past',\n",
       " 'pointclear',\n",
       " u'quicken',\n",
       " u'section',\n",
       " u'undecided',\n",
       " u'seemed',\n",
       " u'method',\n",
       " u'full',\n",
       " u'hash',\n",
       " u'empower',\n",
       " u'november',\n",
       " u'oneyou',\n",
       " u'examplary',\n",
       " u'introductory',\n",
       " u'experience',\n",
       " u'prior',\n",
       " u'periodic',\n",
       " u'bifasic',\n",
       " u'social',\n",
       " u'onpremise',\n",
       " u'followed',\n",
       " u'verbose',\n",
       " u'vid',\n",
       " 'nitesh',\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pplus(adjlist, lp, ln, pp,pn):\n",
    "    if type(adjlist) == list:\n",
    "        pos = np.exp(np.sum([lp[a] for a in adjlist]))\n",
    "        neg = np.exp(np.sum([ln[a] for a in adjlist]))\n",
    "        \n",
    "    else:\n",
    "        pos = np.sum(lp[adjlist])\n",
    "        neg = np.sum(ln[adjlist])\n",
    "        \n",
    "    pplus=1./(1. + (neg*pn)/(pos*pp))\n",
    "    return pplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = df[\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46887"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_topic(ldamodel, bow):\n",
    "    tee = ldamodel.get_document_topics(bow)\n",
    "    if len(tee)==2:\n",
    "        t1,t2=tee\n",
    "        if t2[1] >= t1[1]:\n",
    "            topicis=t2[0]\n",
    "        else:\n",
    "            topicis=t1[0]\n",
    "    elif len(tee)==1:\n",
    "        teetuple=tee[0]\n",
    "        topicis=teetuple[0]\n",
    "    return topicis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noun_dic = {}\n",
    "for i in xrange(len(df)):\n",
    "    noun = df.iloc[i][\"review\"][0]\n",
    "    topic = max(ldamodel.get_document_topics(dictionary.doc2bow(df.iloc[i][\"review\"][0])), key = lambda i: i[1])\n",
    "    if len(noun) == 0:\n",
    "        noun_dic[i] = \"no topic\"\n",
    "    \n",
    "    elif topic[0] == 0:\n",
    "        noun_dic[i] = \"course content and video quality\"\n",
    "    else:\n",
    "        noun_dic[i] = \"instructor and explanations\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = noun_dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter=0\n",
    "reviewdict={}\n",
    "for i, rid in enumerate(ids):\n",
    "    rlist=[]\n",
    "    nlist, alist = review_parts[i]\n",
    "    ln=len(nlist)\n",
    "    localbow=doc_term_matrix[counter:counter+ln]\n",
    "    for bow, adj, noun in zip(localbow, alist, nlist):\n",
    "        doc=\" \".join([dictionary[e[0]] for e in bow])\n",
    "        pplus=calc_pplus(adj, logpositives, lognegatives, priorp, priorn)\n",
    "        topicis=choose_topic(ldamodel, bow)\n",
    "        ldict={\"topic\": topicis, 'pplus':pplus}\n",
    "        rlist.append(ldict)\n",
    "    reviewdict[rid]=rlist\n",
    "    counter=counter+ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic(x):\n",
    "    if len(reviewdict[x]) == 0:\n",
    "        return \"no topic\"\n",
    "    elif reviewdict[x][0][\"topic\"] == 0:\n",
    "        return \"instructor and his explanations\"\n",
    "    else:\n",
    "        return \"course content and video quality\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pplus(x):\n",
    "    if len(reviewdict[x]) == 0:\n",
    "        return \"no comments\"\n",
    "    elif reviewdict[x][0][\"pplus\"] > 0.5:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"topic\"] = pd.Series(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "747"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"topic\"] == \"no topic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7                             no topic\n",
       "26    course content and video quality\n",
       "35    course content and video quality\n",
       "40     instructor and his explanations\n",
       "48    course content and video quality\n",
       "Name: topic, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"topic\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"reg_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
